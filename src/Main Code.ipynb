{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLlt5BrnX5WH",
        "outputId": "c74d8a2d-1871-4d95-ef90-375bf296308c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d9mq4jIbT_X",
        "outputId": "2bb0a19d-4e15-4792-ecce-e6f8796b13c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trzDkYUwbWmw",
        "outputId": "6711b538-4b2e-4c7b-a4bd-6d6ee0db5918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.5.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.0%2Bcu118-cp311-cp311-linux_x86_64.whl (838.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.4/838.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.5.0+cu118 torchaudio-2.5.0+cu118 torchvision-0.20.0+cu118 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.5.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tBRuprffgFG",
        "outputId": "4a429900-89a4-4108-c2f0-045e729cecae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6yeHU9Icw_n"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared\n",
        "!chmod +x cloudflared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wc3IIFYc3NE",
        "outputId": "54ef4f3c-1755-46be-98bc-bc7fd659738d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting colabcode\n",
            "  Downloading colabcode-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Collecting pyngrok>=5.0.0 (from colabcode)\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting nest-asyncio==1.4.3 (from colabcode)\n",
            "  Downloading nest_asyncio-1.4.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting uvicorn==0.13.1 (from colabcode)\n",
            "  Downloading uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of colabcode to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting colabcode\n",
            "  Downloading colabcode-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting uvicorn==0.13.1 (from colabcode)\n",
            "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting colabcode\n",
            "  Downloading colabcode-0.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting uvicorn==0.13.1 (from colabcode)\n",
            "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting colabcode\n",
            "  Downloading colabcode-0.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok>=5.0.0->colabcode) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colabcode-0.1.1-py3-none-any.whl (4.6 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, colabcode, streamlit\n",
            "Successfully installed colabcode-0.1.1 pydeck-0.9.1 pyngrok-7.2.4 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit colabcode opencv-python numpy pillow scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm8wSQinc317",
        "outputId": "3f54f43d-00e7-414e-c0f5-691a2b8094e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.stats import entropy\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "HOME= r'/content/gdrive/MyDrive/M.ScProject'\n",
        "#HOME_LBP= r'/content/drive/MyDrive/Fused_Train_LBP'\n",
        "#HOME_Thermal= r'/content/drive/MyDrive/Thermal_Train'\n",
        "#HOME_Visual= r'/content/drive/MyDrive/Visual_Train'\n",
        "BASE_DRIVE_PATH = \"/content/gdrive/MyDrive/data\"\n",
        "\n",
        "def apply_sharpen_filter(image):\n",
        "    # Define the sharpening kernel\n",
        "    sharpen_kernel = np.array([[-1, -1, -1],\n",
        "                                [-1, 9, -1],\n",
        "                                [-1, -1, -1]])\n",
        "    # Apply the kernel to the image\n",
        "    sharpened_image = cv2.filter2D(image, -1, sharpen_kernel)\n",
        "    return sharpened_image\n",
        "\n",
        "def morphology_hat_transform(image):\n",
        "    \"\"\"\n",
        "    Compute the Morphology-Hat Transform Image (MT) using the formula:\n",
        "    MT(x, y) = f(x, y) + THT(x, y) + BHT(x, y)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Define a structuring element (kernel) for morphological operations\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "    print(kernel)\n",
        "    # Compute the Top-Hat Transform (THT)\n",
        "    top_hat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
        "\n",
        "    # Compute the Black-Hat Transform (BHT)\n",
        "    black_hat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # Compute the Morphology-Hat Transform (MT)\n",
        "    mt_image = cv2.add(image, cv2.add(top_hat, black_hat))\n",
        "    return mt_image\n",
        "\n",
        "def high_boost_filter(image):\n",
        "    # Define the 3×3 high-boost filter kernel\n",
        "    high_boost_kernel = np.array([[ 0,  -1,  0],\n",
        "                               [-1,  5.3, -1],\n",
        "                               [ 0,  -1,  0]], dtype=np.float32)\n",
        "    # Apply the filter using 2D convolution\n",
        "    high_boost_image = cv2.filter2D(image, -1, high_boost_kernel)\n",
        "    # Clip values to stay within 0-255 range and convert to uint8\n",
        "    high_boost_image = np.clip(high_boost_image, 0, 255).astype(np.uint8)\n",
        "    return high_boost_image\n",
        "\n",
        "def mean_value(image):\n",
        "    return np.mean(image)\n",
        "\n",
        "def max_value(image):\n",
        "    return np.max(image)\n",
        "\n",
        "# To compute weights\n",
        "def compute_weights(ma, mb):\n",
        "    total = abs(ma) + abs(mb)\n",
        "    wa = abs(ma) / total\n",
        "    wb = abs(mb) / total\n",
        "    return wa, wb\n",
        "\n",
        "def dwt_fusion(image1, image2):\n",
        "\n",
        "    image1 = high_boost_filter(image1)\n",
        "    #To Apply DWT on both images (Single-level DWT)\n",
        "    coeffs1 = pywt.dwt2(image1, 'db1')\n",
        "    coeffs2 = pywt.dwt2(image2, 'db1')\n",
        "\n",
        "    # Extract approximation(LL) and detail coefficients\n",
        "    LL1, (LH1, HL1, HH1) = coeffs1\n",
        "    LL2, (LH2, HL2, HH2) = coeffs2\n",
        "\n",
        "    # Mean weighted fusion rule for approximation coefficients\n",
        "    mean_image1 = mean_value(image1)\n",
        "    mean_image2 = mean_value(image2)\n",
        "    w1, w2 = compute_weights(mean_image1, mean_image2)\n",
        "\n",
        "    # Approximation coeffiecient for fused image\n",
        "    LL = w1 * LL1 + w2 * LL2\n",
        "\n",
        "    # Max weighted fusion rule for detail coefficients\n",
        "    max_image1 = max_value(image1)\n",
        "    max_image2 = max_value(image2)\n",
        "    w3, w4 = compute_weights(max_image1, max_image2)\n",
        "\n",
        "    # Detail coefficients to perform fusion\n",
        "    LH = w3 * LH1 + w4 * LH2\n",
        "    HL = w3 * HL1 + w4 * HL2\n",
        "    HH = w3 * HH1 + w4 * HH2\n",
        "\n",
        "    # Reconstruct the fused image using IDWT\n",
        "    fused_image = pywt.idwt2((LL, (LH, HL, HH)), 'db1')\n",
        "    fused_image = np.clip(fused_image, 0, 255).astype(np.uint8)   #np.uint8(fused_image)\n",
        "    #fused_image_final=cv2.resize(fused_image,(640,512))\n",
        "    return fused_image\n",
        "\n",
        "def modal_fusion_dwt(visible_image_path,thermal_image_path,output_folder):\n",
        "    modified_visible = None\n",
        "    modified_thermal = None\n",
        "\n",
        "    #To extractjust the filename from visible image path\n",
        "    filename = os.path.splitext(os.path.basename(visible_image_path))[0]\n",
        "\n",
        "    #os.chdir(output_folder)\n",
        "\n",
        "    visible_image = cv2.imread(visible_image_path)\n",
        "    thermal_image = cv2.imread(thermal_image_path)\n",
        "\n",
        "    # Resize the input images\n",
        "    visible_image = cv2.resize(visible_image, (640, 512))\n",
        "    thermal_image = cv2.resize(thermal_image, (640, 512))\n",
        "\n",
        "    # Convert the image to grayscale if it's in color\n",
        "    if len(visible_image.shape) == 3:\n",
        "        visible_image = cv2.cvtColor(visible_image, cv2.COLOR_BGR2GRAY)\n",
        "    # Convert the image to grayscale if it's in color\n",
        "    if len(thermal_image.shape) == 3:\n",
        "       thermal_image = cv2.cvtColor(thermal_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    modified_visible = morphology_hat_transform(visible_image)\n",
        "    modified_thermal = apply_sharpen_filter(thermal_image)\n",
        "    dwt_fused = dwt_fusion(modified_visible, modified_thermal)\n",
        "\n",
        "    dwt_fused = cv2.resize(dwt_fused, (640, 512))\n",
        "    dwt_fused = cv2.normalize(dwt_fused, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    filename = \"Fused.jpg\"\n",
        "    output_path = os.path.join(output_folder,filename)\n",
        "    cv2.imwrite(output_path,dwt_fused)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def modal_fusion_lbp(rgb_path, thermal_path, output_folder=\"output\", alpha=0.6, beta=0.4):\n",
        "    radii = [1, 3, 5]\n",
        "    num_points = 8\n",
        "    method = 'uniform'\n",
        "\n",
        "    def apply_lbp(image_path):\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "        img = cv2.resize(img, (640, 512))\n",
        "\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Error loading image: {image_path}\")\n",
        "\n",
        "        if len(img.shape) == 3:\n",
        "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            img_gray = img\n",
        "\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        img_eq = clahe.apply(img_gray)\n",
        "\n",
        "        img_smooth = cv2.medianBlur(img_eq, 5)\n",
        "\n",
        "        lbp_combined = np.zeros_like(img_smooth, dtype=np.float32)\n",
        "        for r in radii:\n",
        "            lbp = local_binary_pattern(img_smooth, P=num_points, R=r, method=method)\n",
        "            lbp = cv2.normalize(lbp, None, 0, 255, cv2.NORM_MINMAX)\n",
        "            lbp_combined += lbp\n",
        "\n",
        "        lbp_combined = cv2.normalize(lbp_combined, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        lbp_combined = np.uint8(lbp_combined)\n",
        "\n",
        "        blurred_lbp = cv2.GaussianBlur(lbp_combined, (5, 5), 0)\n",
        "\n",
        "        mask = img_eq > 100\n",
        "        lbp_combined = np.where(mask, lbp_combined, blurred_lbp)\n",
        "\n",
        "        gamma = 1.2 if np.mean(img_eq) < 128 else 0.9\n",
        "        img_gamma = np.power(img_eq / 255.0, gamma) * 255\n",
        "        img_gamma = np.uint8(img_gamma)\n",
        "\n",
        "        final_output = cv2.addWeighted(img_gamma, 0.85, lbp_combined, 0.15, 0)\n",
        "\n",
        "        gaussian_blurred = cv2.GaussianBlur(final_output, (3, 3), 1.0)\n",
        "        final_output = cv2.addWeighted(final_output, 1.5, gaussian_blurred, -0.5, 0)\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    lbp_rgb = apply_lbp(rgb_path)\n",
        "    lbp_thermal = apply_lbp(thermal_path)\n",
        "\n",
        "    if lbp_rgb.shape != lbp_thermal.shape:\n",
        "        print(f\"Resizing thermal image to match RGB dimensions...\")\n",
        "        lbp_thermal = cv2.resize(lbp_thermal, (lbp_rgb.shape[1], lbp_rgb.shape[0]))\n",
        "\n",
        "    gray_norm = lbp_rgb.astype(np.float32) / 255.0\n",
        "    thermal_norm = lbp_thermal.astype(np.float32) / 255.0\n",
        "\n",
        "    fused_image = cv2.addWeighted(gray_norm, alpha, thermal_norm, beta, 0)\n",
        "\n",
        "    fused_image = (fused_image * 255).astype(np.uint8)\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    output_path = os.path.join(output_folder, \"Fused.jpg\")\n",
        "    cv2.imwrite(output_path, fused_image)\n",
        "    return output_path\n",
        "\n",
        "#Information Entropy\n",
        "def compute_entropy(img):\n",
        "  # Compute the histogram of the image with 256 bins,\n",
        "  #covering pixel values from 0 to 255,\n",
        "  # `density=True` to ensure that the histogram is normalized\n",
        "  #(i.e., it represents a probability distribution)\n",
        "  hist, _ = np.histogram(img, bins=256, range=[0, 256], density=True)\n",
        "  # Compute the entropy of the histogram using base 2 (Shannon entropy)\n",
        "  return entropy(hist, base=2)\n",
        "\n",
        "#Mean Gradient\n",
        "def compute_meangradient(img):\n",
        "  # Convert to float for precise calculations\n",
        "  img = img.astype(np.float32)\n",
        "  # Compute gradients in x and y directions\n",
        "  gx, gy = np.gradient(img)  # Difference along rows (x-direction)\n",
        "  # Compute Gradient G using the formula\n",
        "  G = (gx**2 + gy**2) / 2\n",
        "  # Compute Mean Gradient (MG)\n",
        "  MG = np.mean(np.sqrt(G))\n",
        "  return MG\n",
        "\n",
        "#Spatial Frequency\n",
        "def compute_spatialfrequency(img):\n",
        "  M, N = img.shape  # Image dimensions\n",
        "  # Compute row frequency (RF)\n",
        "  RF_squared = np.sum((np.diff(img, axis=1))**2) / (M * N)\n",
        "  RF = np.sqrt(RF_squared)\n",
        "  # Compute column frequency (CF)\n",
        "  CF_squared = np.sum((np.diff(img, axis=0))**2) / (M * N)\n",
        "  CF = np.sqrt(CF_squared)\n",
        "  # Compute spatial frequency (SF)\n",
        "  SF = np.sqrt(RF**2 + CF**2)\n",
        "  return SF\n",
        "\n",
        "def compute_metrics(visible_image_path, thermal_image_path, fused_image_path):\n",
        "  visible_image = cv2.imread(visible_image_path)\n",
        "  thermal_image = cv2.imread(thermal_image_path)\n",
        "  fused_image = cv2.imread(fused_image_path)\n",
        "\n",
        "  # Resize the input images\n",
        "  visible_image = cv2.resize(visible_image, (640, 512))\n",
        "  thermal_image = cv2.resize(thermal_image, (640, 512))\n",
        "  fused_image = cv2.resize(fused_image, (640, 512))\n",
        "  # Convert the image to grayscale if it's in color\n",
        "  visible_image = cv2.cvtColor(visible_image, cv2.COLOR_BGR2GRAY)\n",
        "  thermal_image = cv2.cvtColor(thermal_image, cv2.COLOR_BGR2GRAY)\n",
        "  fused_image = cv2.cvtColor(fused_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  #To Create a dataframe containing Information Entropy,Mean Gradient and Spatial Frequency for\n",
        "  #Visible, Thermal and Fused Images\n",
        "  metrics = {\n",
        "        \"Metric\": [\"Information Entropy\", \"Mean Gradient\", \"Spatial Frequency\"],\n",
        "        \"Visible Image\": [\n",
        "            compute_entropy(visible_image),\n",
        "            compute_meangradient(visible_image),\n",
        "            compute_spatialfrequency(visible_image),\n",
        "        ],\n",
        "        \"Thermal Image\": [\n",
        "            compute_entropy(thermal_image),\n",
        "            compute_meangradient(thermal_image),\n",
        "            compute_spatialfrequency(thermal_image),\n",
        "        ],\n",
        "        \"Fused Image\": [\n",
        "            compute_entropy(fused_image),\n",
        "            compute_meangradient(fused_image),\n",
        "            compute_spatialfrequency(fused_image),\n",
        "        ],\n",
        "    }\n",
        "  return pd.DataFrame(metrics)\n",
        "\n",
        "def pred(img, model):\n",
        "    # Run detection on the provided image.\n",
        "    if st.session_state.fusion_method == \"DWT\":\n",
        "      cmd = f'python /content/gdrive/MyDrive/M.ScProject/yolov9/detect.py --weights /content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt --conf 0.6 --source {img} --device 0 --exist-ok --line-thickness 2'\n",
        "    elif st.session_state.fusion_method == \"LBP\":\n",
        "      cmd = f'python /content/gdrive/MyDrive/M.ScProject/yolov9/detect.py --weights  /content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_lbp.pt --conf 0.6 --source {img} --device 0 --exist-ok --line-thickness 2'\n",
        "    elif st.session_state.fusion_method== \"Thermal (no fusion)\":\n",
        "      cmd= f'python /content/gdrive/MyDrive/M.ScProject/yolov9/detect.py --weights  /content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt --conf 0.6 --source {img} --device 0 --exist-ok --line-thickness 2'\n",
        "    elif st.session_state.fusion_method== \"Visual (no fusion)\":\n",
        "      cmd= f'python /content/gdrive/MyDrive/M.ScProject/yolov9/detect.py --weights  /content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt --conf 0.6 --source {img} --device 0 --exist-ok --line-thickness 2'\n",
        "    os.system(cmd)\n",
        "\n",
        "\n",
        "# st.markdown(\n",
        "#     \"\"\"\n",
        "#     <style>\n",
        "#     body, .stApp {\n",
        "#         background-color: white !important;\n",
        "#         color: black !important;\n",
        "#     }\n",
        "#     h1, h2, h3, h4, h5, h6, p, span, div {\n",
        "#         color: black !important;\n",
        "#     }\n",
        "#     div.stButton > button {\n",
        "#         background-color: #FF4500 !important;\n",
        "#         color: white !important;\n",
        "#         border-radius: 10px !important;\n",
        "#         border: none !important;\n",
        "#         padding: 10px 20px !important;\n",
        "#         font-size: 16px !important;\n",
        "#         font-weight: bold !important;\n",
        "#     }\n",
        "#     div.stButton > button:hover {\n",
        "#         background-color: #E63900 !important; /* Darker shade on hover */\n",
        "#     }\n",
        "#     </style>\n",
        "#     \"\"\",\n",
        "#     unsafe_allow_html=True\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "st.title(\"Human Detection with Multi Modal Fusion\")\n",
        "\n",
        "# Initialize session state variables\n",
        "if \"uploaded\" not in st.session_state:\n",
        "    st.session_state.uploaded = False\n",
        "if \"fused\" not in st.session_state:\n",
        "    st.session_state.fused = False\n",
        "if \"fusion_path\" not in st.session_state:\n",
        "    st.session_state.fusion_path = \"\"\n",
        "if \"fusion_method\" not in st.session_state:\n",
        "    st.session_state.fusion_method = \"DWT\"  # Default fusion method\n",
        "\n",
        "st.header(\"1. Upload Images\")\n",
        "\n",
        "# Upload the Visual and Thermal images.\n",
        "visual_file = st.file_uploader(\"Upload Visual Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "thermal_file = st.file_uploader(\"Upload Thermal Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# Confirm Upload: Save the uploaded files to Google Drive.\n",
        "if st.button(\"Confirm Upload\"):\n",
        "    if visual_file is not None and thermal_file is not None:\n",
        "        if not os.path.exists(BASE_DRIVE_PATH):\n",
        "            os.makedirs(BASE_DRIVE_PATH)\n",
        "\n",
        "        visual_path = os.path.join(BASE_DRIVE_PATH, \"Visual.jpg\")\n",
        "        thermal_path = os.path.join(BASE_DRIVE_PATH, \"Thermal.jpg\")\n",
        "\n",
        "        with open(visual_path, \"wb\") as f:\n",
        "            f.write(visual_file.getbuffer())\n",
        "        with open(thermal_path, \"wb\") as f:\n",
        "            f.write(thermal_file.getbuffer())\n",
        "\n",
        "        st.success(\"Images have been uploaded and saved to Google Drive.\")\n",
        "        st.session_state.uploaded = True\n",
        "        st.session_state.visual_path = visual_path\n",
        "        st.session_state.thermal_path = thermal_path\n",
        "    else:\n",
        "        st.error(\"Please upload both Visual and Thermal images before confirming.\")\n",
        "\n",
        "# Display the uploaded images.\n",
        "if st.session_state.uploaded:\n",
        "    st.subheader(\"Uploaded Images\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.image(Image.open(st.session_state.visual_path), caption=\"Visual Image\")\n",
        "    with col2:\n",
        "        st.image(Image.open(st.session_state.thermal_path), caption=\"Thermal Image\")\n",
        "\n",
        "st.header(\"2. Fuse Images\")\n",
        "\n",
        "# Dropdown to select fusion technique.\n",
        "fusion_method = st.selectbox(\"Select Fusion Technique\", [\"DWT\", \"LBP\",\"Thermal (no fusion)\",\"Visual (no fusion)\"], index=0)\n",
        "st.session_state.fusion_method = fusion_method\n",
        "\n",
        "# Fusion button.\n",
        "if st.session_state.uploaded:\n",
        "    if st.button(\"Continue\"):\n",
        "        with st.spinner(\"Fusing images...\"):\n",
        "            if st.session_state.fusion_method == \"DWT\":\n",
        "                modal_fusion_dwt(st.session_state.visual_path, st.session_state.thermal_path, BASE_DRIVE_PATH)\n",
        "                #compute_metrics(st.session_state.visual_path, st.session_state.thermal_path, fused_path)\n",
        "                st.session_state.fused = True\n",
        "                st.success(f\"Fusion complete using {st.session_state.fusion_method}. Fused image saved as 'Fused.jpg'.\")\n",
        "            elif st.session_state.fusion_method == \"LBP\":\n",
        "                modal_fusion_lbp(st.session_state.visual_path, st.session_state.thermal_path, BASE_DRIVE_PATH)\n",
        "                #compute_metrics(st.session_state.visual_path, st.session_state.thermal_path, fused_path)\n",
        "                st.session_state.fused = True\n",
        "                st.success(f\"Fusion complete using {st.session_state.fusion_method}. Fused image saved as 'Fused.jpg'.\")\n",
        "            elif st.session_state.fusion_method== \"Thermal (no fusion)\":\n",
        "                output_path = os.path.join(BASE_DRIVE_PATH, \"Fused.jpg\")\n",
        "                thermal_img = cv2.imread(st.session_state.thermal_path, cv2.IMREAD_UNCHANGED)\n",
        "                thermal_img = cv2.resize(thermal_img, (640, 512))\n",
        "                cv2.imwrite(output_path,thermal_img)\n",
        "                st.success(f\"Continuing with Thermal image only\")\n",
        "                st.session_state.fused = False\n",
        "            elif st.session_state.fusion_method== \"Visual (no fusion)\":\n",
        "                output_path = os.path.join(BASE_DRIVE_PATH, \"Fused.jpg\")\n",
        "                visual_img = cv2.imread(st.session_state.visual_path, cv2.IMREAD_UNCHANGED)\n",
        "                visual_img = cv2.resize(visual_img, (640, 512))\n",
        "                cv2.imwrite(output_path,visual_img)\n",
        "                st.success(f\"Continuing with Visual image only\")\n",
        "                st.session_state.fused = False\n",
        "\n",
        "        st.session_state.fusion_path = os.path.join(BASE_DRIVE_PATH, \"Fused.jpg\")\n",
        "else:\n",
        "    st.info(\"Please upload and confirm images to enable fusion.\")\n",
        "\n",
        "# Display the fused image and the quality metrics comparison table.\n",
        "if st.session_state.fused and st.session_state.fusion_method!= \"Thermal (no fusion)\" and st.session_state.fusion_method!= \"Visual (no fusion)\":\n",
        "    if os.path.exists(st.session_state.fusion_path):\n",
        "        st.subheader(\"Fused Image\")\n",
        "        st.image(Image.open(st.session_state.fusion_path), caption=\"Fused Image\")\n",
        "        metrics_df = compute_metrics(st.session_state.visual_path, st.session_state.thermal_path, st.session_state.fusion_path)\n",
        "        st.subheader(\"Quality Metrics Table\")\n",
        "        st.dataframe(metrics_df)\n",
        "        # Style the DataFrame\n",
        "        styled_df = metrics_df.style.set_caption(\"**IE - Information Entropy, MG - Mean Gradient, SF - Spatial Frequency**\") \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'caption',\n",
        "        'props': [('color', 'blue'), ('font-size', '16px'), ('font-weight', 'bold'), ('text-align', 'center')]\n",
        "    }]) \\\n",
        "    .set_properties(**{\n",
        "        'text-align': 'center',\n",
        "        'background-color': '#f0f0f0',\n",
        "        'border': '1px solid #ddd',\n",
        "        'font-size': '14px'\n",
        "    })\n",
        "    else:\n",
        "        st.error(\"Fused image not found. Please ensure the fusion process completed successfully.\")\n",
        "\n",
        "st.header(\"3. Predict\")\n",
        "\n",
        "# Prediction button.\n",
        "if st.session_state.fused or st.session_state.fusion_method== \"Thermal (no fusion)\" or st.session_state.fusion_method== \"Visual (no fusion)\":\n",
        "    if st.button(\"Predict\"):\n",
        "        with st.spinner(\"Running detection...\"):\n",
        "            pred(st.session_state.fusion_path, st.session_state.fusion_method)\n",
        "        st.success(\"Detection complete.\")\n",
        "        if st.session_state.fusion_method == \"DWT\":\n",
        "          predicted_img_path = os.path.join(HOME, \"yolov9\", \"runs\", \"detect\", \"exp\", os.path.basename(st.session_state.fusion_path))\n",
        "        elif st.session_state.fusion_method == \"LBP\":\n",
        "          predicted_img_path = os.path.join(HOME, \"yolov9\", \"runs\", \"detect\", \"exp\", os.path.basename(st.session_state.fusion_path))\n",
        "        elif st.session_state.fusion_method== \"Thermal (no fusion)\":\n",
        "          predicted_img_path = os.path.join(HOME, \"yolov9\", \"runs\", \"detect\", \"exp\", os.path.basename(st.session_state.fusion_path))\n",
        "        elif st.session_state.fusion_method== \"Visual (no fusion)\":\n",
        "          predicted_img_path = os.path.join(HOME, \"yolov9\", \"runs\", \"detect\", \"exp\", os.path.basename(st.session_state.fusion_path))\n",
        "\n",
        "\n",
        "        if os.path.exists(predicted_img_path):\n",
        "            st.image(Image.open(predicted_img_path), caption=\"Predicted Image\")\n",
        "        else:\n",
        "            st.error(\"Predicted image not found. Please check if detection ran successfully.\")\n",
        "else:\n",
        "    st.info(\"Please complete the fusion step to enable prediction.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw_JH3IRd9fS",
        "outputId": "e49523ee-ba7c-4bea-dd7e-65626b1514fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-04-20T12:44:21Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-04-20T12:44:21Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.143.152.140:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m |  https://monetary-killing-therapist-cooking.trycloudflare.com                              |\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.4.0 (Checksum df13e7e0a027f648c410b5cc701fbcff028724d0e93209796cdbb79ec38695d4)\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.10, GoArch: amd64\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: f2d9abb3-835f-4ca0-aa37-34e6daefc7c8\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Using [CurveID(4588) CurveID(25497) CurveP256] as curve preferences \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23\n",
            "2025/04/20 12:44:27 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-04-20T12:44:27Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m388b965f-54d2-4be1-912f-4d83c91e652d \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mlocation=\u001b[0msin15 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-04-20T12:44:43Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 41 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:43Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 41 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/media/SourceSansPro-SemiBold.sKQIyTMz.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:43Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 53 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:43Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 53 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/media/SourceSansPro-Bold.-6c9oR8J.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:44Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:44Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:44Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 45 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:44Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 45 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/js/index.B-cSXLfy.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 65 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 65 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/js/index.B-cSXLfy.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 61 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 61 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/media/SourceSansPro-Bold.-6c9oR8J.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 73 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-04-20T12:44:45Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 73 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://monetary-killing-therapist-cooking.trycloudflare.com/static/media/SourceSansPro-SemiBold.sKQIyTMz.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 4 persons, 52.8ms\n",
            "Speed: 0.6ms pre-process, 52.8ms inference, 86.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 74.6ms\n",
            "Speed: 0.6ms pre-process, 74.6ms inference, 136.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "[[1 1]\n",
            " [1 1]]\n",
            "/content/gdrive/MyDrive/data/app.py:65: RuntimeWarning: overflow encountered in scalar add\n",
            "  total = abs(ma) + abs(mb)\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 3 persons, 52.6ms\n",
            "Speed: 0.6ms pre-process, 52.6ms inference, 94.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 (no detections), 50.5ms\n",
            "Speed: 0.6ms pre-process, 50.5ms inference, 23.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 1 person, 81.7ms\n",
            "Speed: 0.5ms pre-process, 81.7ms inference, 131.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_lbp.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 52.2ms\n",
            "Speed: 0.5ms pre-process, 52.2ms inference, 98.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "[[1 1]\n",
            " [1 1]]\n",
            "/content/gdrive/MyDrive/data/app.py:65: RuntimeWarning: overflow encountered in scalar add\n",
            "  total = abs(ma) + abs(mb)\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 58.3ms\n",
            "Speed: 0.6ms pre-process, 58.3ms inference, 102.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 4 persons, 61.5ms\n",
            "Speed: 0.5ms pre-process, 61.5ms inference, 99.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 52.9ms\n",
            "Speed: 0.5ms pre-process, 52.9ms inference, 89.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 4 persons, 71.2ms\n",
            "Speed: 0.6ms pre-process, 71.2ms inference, 102.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 75.7ms\n",
            "Speed: 0.6ms pre-process, 75.7ms inference, 112.6ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "[[1 1]\n",
            " [1 1]]\n",
            "/content/gdrive/MyDrive/data/app.py:65: RuntimeWarning: overflow encountered in scalar add\n",
            "  total = abs(ma) + abs(mb)\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 3 persons, 54.4ms\n",
            "Speed: 0.6ms pre-process, 54.4ms inference, 85.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 (no detections), 77.3ms\n",
            "Speed: 0.5ms pre-process, 77.3ms inference, 17.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 1 person, 50.9ms\n",
            "Speed: 0.5ms pre-process, 50.9ms inference, 90.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_lbp.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 52.4ms\n",
            "Speed: 0.6ms pre-process, 52.4ms inference, 89.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "[[1 1]\n",
            " [1 1]]\n",
            "/content/gdrive/MyDrive/data/app.py:65: RuntimeWarning: overflow encountered in scalar add\n",
            "  total = abs(ma) + abs(mb)\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 55.8ms\n",
            "Speed: 0.6ms pre-process, 55.8ms inference, 92.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 (no detections), 57.6ms\n",
            "Speed: 0.5ms pre-process, 57.6ms inference, 14.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 1 person, 55.1ms\n",
            "Speed: 0.5ms pre-process, 55.1ms inference, 95.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "[[1 1]\n",
            " [1 1]]\n",
            "/content/gdrive/MyDrive/data/app.py:65: RuntimeWarning: overflow encountered in scalar add\n",
            "  total = abs(ma) + abs(mb)\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 77.7ms\n",
            "Speed: 0.5ms pre-process, 77.7ms inference, 119.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_lbp.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 54.0ms\n",
            "Speed: 0.5ms pre-process, 54.0ms inference, 89.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_vis.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 4 persons, 50.8ms\n",
            "Speed: 0.5ms pre-process, 50.8ms inference, 91.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_thermal.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 2 persons, 54.6ms\n",
            "Speed: 0.5ms pre-process, 54.6ms inference, 86.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "[[1 1]\n",
            " [1 1]]\n",
            "/content/gdrive/MyDrive/data/app.py:65: RuntimeWarning: overflow encountered in scalar add\n",
            "  total = abs(ma) + abs(mb)\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/M.ScProject/yolov9/runs/train/exp3/weights/best_dwt.pt'], source=/content/gdrive/MyDrive/data/Fused.jpg, data=../M.ScProject/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../M.ScProject/yolov9/runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.12 torch-2.5.0+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/gdrive/MyDrive/M.ScProject/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/data/Fused.jpg: 512x640 3 persons, 55.7ms\n",
            "Speed: 0.6ms pre-process, 55.7ms inference, 87.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../M.ScProject/yolov9/runs/detect/exp\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[90m2025-04-20T12:56:52Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-04-20T12:56:53Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23\n",
            "\u001b[90m2025-04-20T12:56:53Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23\n",
            "\u001b[90m2025-04-20T12:56:53Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-04-20T12:56:53Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-04-20T12:56:53Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & ./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DFmhnf2__gL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}